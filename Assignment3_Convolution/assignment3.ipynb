{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Composition with Convolutional Maps\n",
    "Use the following code to experiment with convolving different samples. When you find an interesting creation, save it to use in your assignment by clicking on the three dots in the sample player and selecting \"Download\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /srv/conda/lib/python3.11/site-packages (0.11.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /srv/conda/lib/python3.11/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /srv/conda/lib/python3.11/site-packages (from librosa) (0.61.2)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /srv/conda/lib/python3.11/site-packages (from librosa) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /srv/conda/lib/python3.11/site-packages (from librosa) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /srv/conda/lib/python3.11/site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: joblib>=1.0 in /srv/conda/lib/python3.11/site-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /srv/conda/lib/python3.11/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /srv/conda/lib/python3.11/site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /srv/conda/lib/python3.11/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /srv/conda/lib/python3.11/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /srv/conda/lib/python3.11/site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /srv/conda/lib/python3.11/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /srv/conda/lib/python3.11/site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: packaging in /srv/conda/lib/python3.11/site-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /srv/conda/lib/python3.11/site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /srv/conda/lib/python3.11/site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /srv/conda/lib/python3.11/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /srv/conda/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /srv/conda/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /srv/conda/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /srv/conda/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.8.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /srv/conda/lib/python3.11/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /srv/conda/lib/python3.11/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /srv/conda/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa\n",
    "import matplotlib.pyplot as plt \n",
    "from ipywidgets import widgets\n",
    "from IPython.display import Audio, display, clear_output\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "SR = 44100\n",
    "\n",
    "def next_power_of_2(x):  \n",
    "    return 1 if x == 0 else 2**(x - 1).bit_length()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listen to some samples\n",
    "Use the dropdown below to listen to the different samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4e274a3a3140e1b90f9c2f786408d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Sample:', options=('Volume.wav', 'Molinera_mono.wav', 'DonaStereoMono.wav…"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_list = [str(file.name) for file in Path('./samples').iterdir() if file.is_file()]\n",
    "\n",
    "sample_dropdown = widgets.Dropdown(\n",
    "    options=sample_list,\n",
    "    description=\"Sample:\"\n",
    ")\n",
    "\n",
    "# Create a button widget\n",
    "listen_button = widgets.Button(description=\"Listen\")\n",
    "\n",
    "# Create an Output widget to display the generated music\n",
    "listen_output_widget = widgets.Output()\n",
    "\n",
    "# Define a function to be called when the button is clicked\n",
    "def on_listen_button_click(b):\n",
    "    with listen_output_widget:\n",
    "        clear_output(wait=True)\n",
    "        path = Path('./samples') / sample_dropdown.value\n",
    "        x, _ = librosa.load(path, sr=SR)\n",
    "        display(Audio(x, rate=SR))\n",
    "\n",
    "# Attach the function to the button's click event\n",
    "listen_button.on_click(on_listen_button_click)\n",
    "\n",
    "# Display the widgets and button\n",
    "widgets.VBox([sample_dropdown, listen_button, listen_output_widget])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolve two samples\n",
    "Use the following code to convolve two samples together. You can use the output of this in your assignment.\n",
    "\n",
    "With sound files we are in the time domain which enables us to use the Convolution Theorem. The theorem states that convolution in the time domain is the same as complex multiplication in the frequency domain. In other words, multiplying the frequency content (spectra) of two signals is the same as performing convolution. So, \n",
    "\n",
    "$$ y(t) = x(t) * h(t) = IFFT(X(k)H(k)) $$ \n",
    "\n",
    "where $X(k)$ and $H(k)$ are frequency representations of the signals $x$ and $h$, and $y$ is our convolved signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5336f9f14b424a08a154ee5ac9e0e381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Sample 1:', options=('Volume.wav', 'Molinera_mono.wav', 'DonaStereoMono.w…"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_list = [str(file.name) for file in Path('./samples').iterdir() if file.is_file()]\n",
    "\n",
    "def convolve(x, h):\n",
    "    # the FFT is most efficient when the length of the signal is a power of two\n",
    "    if x.size > h.size:\n",
    "        N = next_power_of_2(x.size)\n",
    "    else:\n",
    "        N = next_power_of_2(h.size)\n",
    "\n",
    "    # calculate the real part of the FFT for each signal \n",
    "    x_fft = np.fft.rfft(x, N)\n",
    "    h_fft = np.fft.rfft(h, N)\n",
    "\n",
    "    # multiply the two signals\n",
    "    convolved = x_fft * h_fft\n",
    "\n",
    "    # use IFFT to convert to time domain signal\n",
    "    y = np.fft.irfft(convolved)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "# Create Dropdown widgets for the two samples\n",
    "x_dropdown = widgets.Dropdown(\n",
    "    options=sample_list,\n",
    "    description=\"Sample 1:\",  \n",
    ")\n",
    "\n",
    "h_dropdown = widgets.Dropdown(\n",
    "    options=sample_list,\n",
    "    description=\"Sample 2:\"\n",
    ")\n",
    "\n",
    "# Create a button widget\n",
    "convolve_button = widgets.Button(description=\"Convolve\")\n",
    "\n",
    "# Create an Output widget to display the generated music\n",
    "convolve_output_widget = widgets.Output()\n",
    "\n",
    "# Define a function to be called when the button is clicked\n",
    "def on_convolve_button_click(b):\n",
    "    with convolve_output_widget:\n",
    "        clear_output(wait=True)  # Clear the output widget without clearing the dropdowns\n",
    "        print(f\"Convolving {x_dropdown.value} and {h_dropdown.value}\")\n",
    "        path1 = Path('./samples') / x_dropdown.value\n",
    "        path2 = Path('./samples') / h_dropdown.value\n",
    "        x, _ = librosa.load(path1, sr=SR)\n",
    "        h, _ = librosa.load(path2, sr=SR)\n",
    "        y = convolve(x, h)\n",
    "        print(\"Convolution complete\")\n",
    "        display(Audio(y, rate=SR))\n",
    "\n",
    "# Attach the function to the button's click event\n",
    "convolve_button.on_click(on_convolve_button_click)\n",
    "\n",
    "# Display the widgets and button\n",
    "widgets.VBox([x_dropdown, h_dropdown, convolve_button, convolve_output_widget])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
